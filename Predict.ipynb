{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import preprocess\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "# from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, Concatenate\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "PATH_TRAIN = '/home/deepenoughlearning/ImageSegmentation/preprocessed'\n",
    "PATH_TRAIN_IMAGES = '/home/deepenoughlearning/ImageSegmentation/preprocessed/original'\n",
    "PATH_TRAIN_MASKS = '/home/deepenoughlearning/ImageSegmentation/preprocessed/mask'\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1. - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "# Custom IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "\n",
    "# Custom loss function\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def data_gen(img_folder, mask_folder, batchsize):\n",
    "    num_training_images = os.listdir(img_folder)\n",
    "    random.shuffle(num_training_images)  # then what happens to the mask folder?\n",
    "    # it's necessary for yield\n",
    "    start = 0\n",
    "    while (True):\n",
    "        img = np.zeros((batchsize, 1040, 2000, 1)).astype('float')\n",
    "        mask = np.zeros((batchsize, 1040, 2000, 1)).astype('float')\n",
    "        for i in range(start, batchsize):\n",
    "            train_img = cv2.imread(img_folder + '/' + num_training_images[i], cv2.IMREAD_GRAYSCALE) / 255.\n",
    "            img[i - start] = train_img\n",
    "            train_mask = cv2.imread(mask_folder + '/' + num_training_images[i], cv2.IMREAD_GRAYSCALE) / 255.\n",
    "            mask[i - start] = train_mask\n",
    "\n",
    "        start += batchsize\n",
    "        if (start + batchsize >= len(num_training_images)):\n",
    "            start = 0\n",
    "            random.shuffle(num_training_images)\n",
    "\n",
    "        yield img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '/home/deepenoughlearning/keract')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/deepenoughlearning/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/deepenoughlearning/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"me...)`\n"
     ]
    }
   ],
   "source": [
    "def get_unet(img_rows, img_cols):\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d1')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d2')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), name='maxpooling2d1')(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d3')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d4')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), name='maxpooling2d2')(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d5')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d6')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), name='maxpooling2d3')(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d7')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d8')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), name='maxpooling2d4')(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d9')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='conv2d10')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal', name='upsampleconv2d1')(\n",
    "        UpSampling2D(size=(2, 2), name='upsampling2d1')(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d1')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d2')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal', name='upsampleconv2d2')(\n",
    "        UpSampling2D(size=(2, 2), name='upsampling2d2')(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d3')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d4')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal', name='upsampleconv2d3')(\n",
    "        UpSampling2D(size=(2, 2), name='upsampling2d3')(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d5')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d6')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal', name='upsampleconv2d4')(\n",
    "        UpSampling2D(size=(2, 2), name='upsampling2d4')(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d7')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d8')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal', name='mergeconv2d9')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid', name='mergeconv2d10')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=bce_dice_loss, metrics=[dice_coef_loss])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = get_unet(1040, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n",
      "suhyun\n",
      "(196, 1040, 2000, 1)\n",
      "three\n",
      "four\n",
      "five\n",
      "Found 196 images belonging to 1 classes.\n",
      "six\n",
      "Found 196 images belonging to 1 classes.\n",
      "seven\n",
      "eight\n",
      "WARNING:tensorflow:From /home/deepenoughlearning/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"me...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "98/98 [==============================] - 142s 1s/step - loss: 5.4319 - dice_coef_loss: 0.9470\n",
      "\n",
      "Epoch 00001: loss improved from inf to 5.43190, saving model to unet-7-27.h5\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 120s 1s/step - loss: 4.8870 - dice_coef_loss: 0.9809\n",
      "\n",
      "Epoch 00002: loss improved from 5.43190 to 4.88699, saving model to unet-7-27.h5\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 120s 1s/step - loss: 4.9558 - dice_coef_loss: 0.9704\n",
      "\n",
      "Epoch 00003: loss did not improve from 4.88699\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 120s 1s/step - loss: -0.0904 - dice_coef_loss: 0.5512\n",
      "\n",
      "Epoch 00004: loss improved from 4.88699 to -0.09044, saving model to unet-7-27.h5\n",
      "Epoch 5/5\n",
      "98/98 [==============================] - 120s 1s/step - loss: -0.0595 - dice_coef_loss: 0.5701\n",
      "\n",
      "Epoch 00005: loss did not improve from -0.09044\n"
     ]
    }
   ],
   "source": [
    "print(\"one\")\n",
    "image_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   rotation_range=10\n",
    "                                   )\n",
    "print(\"two\")\n",
    "mask_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  width_shift_range=0.1,\n",
    "                                  height_shift_range=0.1,\n",
    "                                  zoom_range=0.1,\n",
    "                                  rotation_range=10\n",
    "                                  )\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "\n",
    "filelist_images = glob.glob(os.path.join(PATH_TRAIN + '/original/cavity/', '*.jpg'))\n",
    "filelist_masks = glob.glob(os.path.join(PATH_TRAIN + '/mask/cavity/', '*.jpg'))\n",
    "\n",
    "filelist_images = preprocess.quicksort(filelist_images)\n",
    "filelist_masks = preprocess.quicksort(filelist_masks)\n",
    "\n",
    "train_loaded_images = []\n",
    "train_loaded_masks = []\n",
    "\n",
    "for image in filelist_images:\n",
    "    img = cv2.imread(image, 0)  # reading grayscale images. without it, it will have 3 color channels\n",
    "    newimg = np.zeros((1040, 2000, 1), dtype=int)\n",
    "    newimg[:, :, 0] = img[:, :]\n",
    "    train_loaded_images.append(newimg)\n",
    "\n",
    "train_loaded_images = np.array(train_loaded_images)\n",
    "\n",
    "print(\"suhyun\")\n",
    "print(train_loaded_images.shape)\n",
    "\n",
    "for mask in filelist_masks:\n",
    "    newimg = np.zeros((1040, 2000, 1), dtype=int)\n",
    "    msk = cv2.imread(mask, 0)\n",
    "    newimg[:, :, 0] = msk[:, :]\n",
    "    train_loaded_masks.append(newimg)\n",
    "\n",
    "    \n",
    "print(\"three\")\n",
    "image_datagen.fit(train_loaded_images, augment=True, seed=seed)\n",
    "print(\"four\")\n",
    "mask_datagen.fit(train_loaded_masks, augment=True, seed=seed)\n",
    "\n",
    "print(\"five\")\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    batch_size=1,\n",
    "    directory=PATH_TRAIN_IMAGES,\n",
    "    class_mode=None,\n",
    "    target_size=(1040, 2000),\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "print(\"six\")\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    batch_size=1,\n",
    "    directory=PATH_TRAIN_MASKS,\n",
    "    class_mode=None,\n",
    "    target_size=(1040, 2000),\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "print(\"seven\")\n",
    "\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "print(\"eight\")\n",
    "\n",
    "# steps_per_epoch = number of batch iterations before a training epoch is considered finished.\n",
    "batch_size = 1\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop = EarlyStopping(monitor='loss', min_delta=0.001, patience=3, mode='min', verbose=1)\n",
    "checkpoint = ModelCheckpoint('unet-7-27.h5', monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_steps=2, steps_per_epoch=len(train_loaded_images) / (batch_size * 2), epochs=5,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "model.save_weights(\"unet-8-7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('unet-7-27.h5')\n",
    "img = np.zeros((1, 1040, 2000, 1), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = cv2.imread(PATH_TRAIN_IMAGES + '/cavity/' + \"186.jpg\", 0)\n",
    "    \n",
    "img[0, :, :, 0] = train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1040, 2000, 1)\n",
      "(1040, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "print(train_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Could not allocate ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;31mMemoryError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function TF_SessionRunCallable> returned a result with an error set",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-873f98ed44a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeract\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/keract/keract/keract.py\u001b[0m in \u001b[0;36mget_activations\u001b[0;34m(model, x, layer_name)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0minput_layer_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0minput_layer_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'input_'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mactivations_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mactivations_inputs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_layer_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/keract/keract/keract.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(model, nodes_to_evaluate, x, y)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymb_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_to_evaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weight_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Could not allocate ndarray"
     ]
    }
   ],
   "source": [
    "from keract import get_activations\n",
    "activations = get_activations(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 409ms/step\n",
      "(1, 1040, 2000, 1)\n"
     ]
    }
   ],
   "source": [
    "activations = model.predict(img, verbose=1)\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f66a53263b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirst_layer_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_layer_activation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "first_layer_activation = activations[1]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(\"upsampling2d1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 398ms/step\n",
      "nine\n",
      "(1040, 2000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_sample(X):\n",
    "    newx = np.zeros((1040, 2000), dtype=int)\n",
    "    newx[:, :] = X[0, :, :, 0]\n",
    "    print(newx.shape)\n",
    "    xplot = plt.imshow(newx)\n",
    "\n",
    "\n",
    "mask = np.zeros((1, 1040, 2000, 1), dtype=int)\n",
    "mask_img = cv2.imread(PATH_TRAIN_MASKS + '/cavity/' + \"109.jpg\", 0)\n",
    "mask[0, :, :, 0] = mask_img\n",
    "\n",
    "print(\"nine\")\n",
    "\n",
    "plot_sample(preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
